---
layout: post
title: "Intelligently Artificial F.C."
subtitle: "A Robocup Simulation League Team."
share-img: "/img/robocup/still.png"
tags: [project, code]
---

<div>
	<blockquote cite="https://en.wikipedia.org/wiki/RoboCup">
		<p>
			RoboCup is an annual international robotics competition. The aim is to promote robotics and AI research, by offering a publicly appealing, but formidable challenge.
		</p>
		The official goal of the project:
		<br>
		<blockquote>
			"By the middle of the 21st century, a team of fully autonomous humanoid robot soccer players shall win a soccer game, complying with the official rules of FIFA, against the winner of the most recent World Cup."			
		</blockquote>
	</blockquote>
</div>

Originally done as coursework for the Artificial Intelligence module at University. Students were split into groups, with each group developing their own AI to play football. At the end of the module, all of the teams played against each other. A video of our team playing a very basic AI is below.

<div class="text-center">
	<iframe src="https://player.vimeo.com/video/155558305" width="500" height="264" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
</div>

The code is available [here](https://github.com/JamesFrost/robocup), and the Javadoc is available [here](http://ragnarula.github.io/robocup).

## Design
This Robocup simulation team is designed around the concept of a one-way data flow. Our model is re-created at every simulation step. The process begins with the server sending our ```ControllerPlayer``` information via the ```info*``` methods. Once all the information is gathered into a Percept, a new model object is created. This model object is passed sequentially through a chain of "AI Components" (in package ```ai```) that implement the ```IChainable``` Interface via the ```ai.AbstractSimpleAIComponent``` abstract class.

Each component is responsible for adding more information in to the model by using information contained in the percept. This could be simple information such as the current play mode, or involve more complex calculations such as to determine the agent's current location.

By the time the model has passed through all the components the model should contain enough information to determine what set of actions need to be executed. Actions are executed in the final component, the ```AgentActionAIComponent```. Here the state design pattern is used to organise the agent's behaviour.

This architecture was implemented to allow us to use asynchronous components with message passing rather than shared state.

The concept is illustrated in the diagram below.

<img src="/img/robocup/dataflow.jpg">
